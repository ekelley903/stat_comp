---
title: "HW3"
author: "E. Kelley"
date: "9/30/2022"
output: pdf_document
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, include = TRUE, warning = FALSE, message = FALSE)
```

```{r}
suppressPackageStartupMessages(library(tidyverse))
```

## Exercise 1

A: 
- just 10% since it is in one dimension.
B:
- two dimensions this time, so we have 0.1 x 0.1 = .01

C: 
- for 100 dimensions we take .1 ^ 100 = 1e-100 of observations available to make 

D:
- We can see when we are low dimensions as seen in A and B, we still have a decent chance of samples existing near our unknown sample, but when we add additional dimensions, as in C, we quickly lose the ability to identify a nearest neighbor.  





## Exercise 2
### a.
```{r}
library(alr4)
data("fuel2001")
fuel2001 <- fuel2001 %>% 
  select(FuelC, Pop, Drivers)
```

### b. All three are highly correlated. Drivers is most correlated with FuelC, so should produce a better predictive model.
```{r}
cmat <- cor(fuel2001)
cmat

#overkill
# library(corrplot)
# corrplot(cmat) 
# ggplot(fuel2001, aes(log10(Drivers), log10(FuelC))) + geom_point()
```


### c.  

```{r}
library(ISLR)
set.seed(1)
train = sample(51, 34)

m1 <- lm(FuelC ~ Pop, data = fuel2001, subset=train)
m2 <- lm(FuelC ~ Drivers, data = fuel2001, subset=train)
m3 <- lm(FuelC ~ Pop + Drivers, data = fuel2001, subset=train)

# map(list(m1,m2,m3), ~summary(.x))

get_mse <- function(m) {
  attach(fuel2001)  
  mean((FuelC - predict(m, fuel2001))[-train]^2)
}

all_mse <- map_dbl(list(m1,m2,m3), ~get_mse(.x)) %>%
  format(., scientific=T)
names(all_mse) <- c("Pop", "Drivers", "both")
```

As expected from the correlation analysis, the model including Drivers only had the lowest MSE, followed by the model with both, and finally the model with Population only. 
```{r}
knitr::kable(all_mse, col.names = "MSE")
```

### d.
```{r}
cv_lm <- function(train_prop){
  drv_mse_cv_vec <- c()
  
  train_size = as.integer(nrow(fuel2001) * train_prop)
  # print(paste("train size: ", train_size))
    data <- fuel2001
    
    train <- data %>%
      mutate(row_id=row_number()) %>%
      sample_n(train_size)
    
    # print(glimpse(train))
    
    test <- data %>%
      mutate(row_id=row_number()) %>%
      filter(!(row_id %in% train$row_id))
    # print(paste0("dim of test ", dim(test)))
    get_mse <- function(m) {
      mean((test$FuelC - predict(m, newdata = test))^2)
    }
    
       # just driver model
    drv <- lm(FuelC ~ Drivers, data = train)
    drv_mse <- get_mse(drv)
    # print(paste0("drv_mse ", drv_mse))
    drv_mse_cv_vec <- append(drv_mse_cv_vec, drv_mse)
   
    
  cv_df <- data.frame(drv_mse_cv_vec)
  return(cv_df)
}

train_props <- seq(.4, .7, .05)
names(train_props) <- as.character(paste0("prop_", train_props))

cv_mse_list <- list()
for (i in seq(1:1000)){
  cv_map <- imap_dfr(train_props, ~cv_lm(.x), .id = "train_props")
  cv_mse_list[[i]] <- cv_map
}

all_cv_lm <- bind_rows(cv_mse_list) %>%
  set_names(c("train_props", "drivers_mse"))

all_cv_lm2 <- all_cv_lm %>%
  dplyr::group_by(train_props) %>%
  dplyr::mutate(mean_drivers_mse = format(mean(drivers_mse), scientific=T)) %>%
  mutate(var_drivers_mse = var(drivers_mse)) %>%
  ungroup() %>%
  distinct(., .keep_all = T) %>%
  mutate(train_prop_num = as.numeric(str_sub(train_props, start = 6))) %>%
  select(train_prop_num, mean_drivers_mse, var_drivers_mse) %>%
  distinct(., .keep_all = T)

knitr::kable(all_cv_lm2)

```

As you can see from the table of mean MSE and variance of MSE, as the training proportion increases, we see an increase in the variance of the MSE for the validation set.  The mean MSE reaches its minimum at 0.65, so that may be a good choice of proportion for training with less bias than the lower proportions, but the variance is higher. I would consider using the 0.55 proportion since it seems to have a good balance of bias and variance.

## Exercise 3
```{r}
beta_0 <- -6
beta_1 <- 0.05
beta_2 <- 1
# ISL equation 4.3 gives odds
# X1 = hours studied
# X2 = undergrad GPA
# Y = received an A

X1 <- 40
X2 <- 3.5

# Review 4.3.4 equation 4.7 
p.X1.X2 <- exp((beta_0 + beta_1*X1 + beta_2*X2)) / (1+ exp((beta_0 + beta_1*X1 + beta_2*X2)))
paste0("The probability of getting an A for 40 hours: ", round(p.X1.X2, digits=2))

# Recall from Chapter 3 that in a linear regression model, B1 gives the
# average change in Y associated with a one-unit increase in X. By contrast,
# in a logistic regression model, increasing X by one unit changes the log
# odds by B1 (4.4)

# p(X1) = 0.5 implies odds of 0.5/1-0.5 = 1 what is X1?

# an increase of 1 hour study time increases log odds of getting an A by 0.05

#log(1) = beta_0 + beta_1*X1 + beta_2*X2
X1.p0.5 <- (-beta_0 - beta_2 * X2)/beta_1 #= X
paste0("The student would need to study for ", X1.p0.5, " hours to increase the probability of getting an A to 0.5.")

#  (6 - 1*3.5) / 0.05 = X1
# check my answer
X1 <- 50
p.X1.X2 <- exp((beta_0 + beta_1*X1 + beta_2*X2)) / (1+ exp((beta_0 + beta_1*X1 + beta_2*X2)))
```

